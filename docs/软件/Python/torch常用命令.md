---
title: torchå¸¸ç”¨å‘½ä»¤
date: 2023-06-12 15:27:15
updated:
categories: 
- å­¦ä¹ 
tags: 
- torch
- æ·±åº¦å­¦ä¹ 
keywords:
- torch
- æ·±åº¦å­¦ä¹ 
description: é€šè¿‡torchæŸ¥çœ‹ä¿¡æ¯
cover: https://pytorch.org/tutorials/_static/img/thumbnails/cropped/profiler.png
top_img: https://imagingsolution.net/wordpress/wp-content/uploads/2022/03/pytorch_logo_icon.png
top: 200
---

# 1ã€æœåŠ¡å™¨ä¿¡æ¯æŸ¥è¯¢

## `CPU`æŸ¥è¯¢

```shell
# æŸ¥çœ‹CPUä¿¡æ¯
cat /proc/cpuinfo | grep "physical id" | uniq | wc -l #æŸ¥çœ‹CPUä¸ªæ•°
cat /proc/cpuinfo | grep "cpu cores" | uniq #æŸ¥çœ‹CPUæ ¸æ•°
cat /proc/cpuinfo | grep 'model name' |uniq #æŸ¥çœ‹CPUå‹å·
```

## `GPU`æŸ¥è¯¢

```shell
# æŸ¥çœ‹GPUä¿¡æ¯
sudo dpkg --list | grep nvidia-* # æŸ¥çœ‹é©±åŠ¨ç‰ˆæœ¬
lshw -c video #æŸ¥çœ‹æ˜¾å¡å‹å·
$ lspci | grep -i nvidia # å¯ä»¥æŸ¥è¯¢æ‰€æœ‰nvidiaæ˜¾å¡
$ lspci -v -s [æ˜¾å¡ç¼–å·] # å¯ä»¥æŸ¥çœ‹æ˜¾å¡å…·ä½“å±æ€§
$ nvidia-smi # å¯ä»¥æŸ¥çœ‹æ˜¾å¡çš„æ˜¾å­˜åˆ©ç”¨ç‡
$ cat /etc/issue # æŸ¥çœ‹Linuxå‘å¸ƒç‰ˆæœ¬å·
$ lsb_release -a # æŸ¥çœ‹Linuxå‘å¸ƒç‰ˆæœ¬å·
$ uname -sr # æŸ¥çœ‹å†…æ ¸ç‰ˆæœ¬å·
$ uname -a # æŸ¥çœ‹å†…æ ¸ç‰ˆæœ¬å·
```

`lspci`æ˜¯ä¸€ç§å®ç”¨ç¨‹åºï¼Œç”¨äºåœ¨ç³»ç»Ÿä¸­æ˜¾ç¤ºæœ‰å…³[pciæ€»çº¿](https://so.csdn.net/so/search?q=pciæ€»çº¿&spm=1001.2101.3001.7020)çš„ä¿¡æ¯ä»¥åŠè¿æ¥åˆ°å®ƒä»¬çš„è®¾å¤‡ã€‚

## `CUDA`ç‰ˆæœ¬

```shell
nvidia-smi # å³ä¸Šè§’CUDA Versionï¼Œä½†å¯èƒ½ä¸å‡†ç¡®ï¼Œæ¨èä½¿ç”¨nvcc -V
nvcc -V # å»ºè®®ä»¥nvcc -VæŸ¥è¯¢ä¸ºä¸»
```

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://cdn.jsdelivr.net/gh/01Petard/imageURL@main/img/19b97250915d432f8af3cea56df6db2c.png)

## å®æ—¶æŸ¥çœ‹`nvidia-smi`

```shell
nvidia-smi -l 1 # ä»¥æ¯ç§’åˆ·æ–°ä¸€æ¬¡è¿›è¡Œä¿¡æ¯ï¼Œç»“æœä¸º1sä¸€æ¬¡è¾“å‡ºnvidia-smiï¼Œä¸æµç•…ï¼Œå»ºè®®ä½¿ç”¨å“ä¸€æ¡å‘½ä»¤
watch -n 1 nvidia-smi # ä¼šåœ¨åŒä¸€ä½ç½®å¤„1sæ›´æ–°çª—å£ä¿¡æ¯
```

# 2ã€æ˜¾å¡ä¿¡æ¯æŸ¥çœ‹

```python
torch.cuda.is_available() # æŸ¥çœ‹æ˜¯å¦æœ‰å¯ç”¨GPU
torch.cuda.device_count() # æŸ¥çœ‹GPUæ•°é‡
torch.cuda.get_device_capability(device) # æŸ¥çœ‹æŒ‡å®šGPUå®¹é‡
torch.cuda.get_device_name(device) # æŸ¥çœ‹æŒ‡å®šGPUåç§°
torch.cuda.empty_cache() # æ¸…ç©ºç¨‹åºå ç”¨çš„GPUèµ„æº
torch.cuda.manual_seed(seed) # è®¾ç½®éšæœºç§å­
torch.cuda.manual_seed_all(seed) # è®¾ç½®éšæœºç§å­
torch.cuda.get_device_properties(i) # iä¸ºç¬¬å‡ å¼ å¡ï¼Œæ˜¾ç¤ºè¯¥å¡çš„è¯¦ç»†ä¿¡æ¯
```

# 3ã€è¾“å‡ºæ¨¡å‹å¢è‚Œä¿¡æ¯

```python
s = f'MODEL ğŸš€ torch {torch.__version__} '
    n = torch.cuda.device_count()
    space = ' ' * (len(s)+1)
    for d in range(n):
        p = torch.cuda.get_device_properties(d)
        s += f"{'' if d == 0 else space}CUDA:{d} ({p.name}, {p.total_memory / 1024 ** 2}MB)\n"  # bytes to MB
    print(s)
```

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://cdn.jsdelivr.net/gh/01Petard/imageURL@main/img/230468572b0048dcb2eb1de6f79a9823.png)

# 4ã€æŒ‡å®šä½¿ç”¨æ˜¾å¡

é€šè¿‡`os.environ["CUDA_VISIBLE_DEVICES"]`æŒ‡å®šæ‰€è¦ä½¿ç”¨çš„æ˜¾å¡ï¼š

```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = "2,1,3,4"
print("torch.cuda.device_count() {}".format(torch.cuda.device_count()))
```

è¿™ç§è®¾ç½®æ–¹å¼ï¼Œ`2`å·å¡å°±å˜æˆäº†ä¸»å¡ã€‚`CUDA_VISIBLE_DEVICES `è¡¨ç¤ºå½“å‰å¯ä»¥è¢«pythonç¯å¢ƒç¨‹åºæ£€æµ‹åˆ°çš„æ˜¾å¡ã€‚`os.environ["CUDA_VISIBLE_DEVICES"] = "2,1,3,4"`è¿›è¡ŒæŒ‡å®šä½¿ç”¨è®¾å¤‡ï¼Œè¿™æ ·ä¼šä¿®æ”¹`pytorch`æ„Ÿå—çš„è®¾å¤‡ç¼–å·ï¼Œ`pytorch`æ„ŸçŸ¥çš„ç¼–å·è¿˜æ˜¯ä»`device:0`å¼€å§‹ã€‚å¦‚ä¸Šä¼šæŠŠ`2`å·æ˜¾å¡æ”¹ä¸º`device:0`ï¼Œ`1`å·æ˜¾å¡æ”¹ä¸º`device:1`ã€‚

å¦‚æœæœ‰å¤šä¸ªæ˜¾å¡ï¼Œè®¾ç½®äº†`os.environ["CUDA_VISIBLE_DEVICES"]`åï¼Œå…¶ä»–æ²¡æœ‰è®¾ç½®çš„æ˜¾å¡å°†ä¸ä¼šåœ¨æœ¬æ¬¡ä»£ç ä¸­æ˜¾ç¤ºã€‚`os.environ["CUDA_VISIBLE_DEVICES"]`éœ€è¦è®¾ç½®åœ¨ä»£ç å¼€å¤´ã€‚

å¦å¤–ï¼Œä½¿ç”¨ç»ˆç«¯ä¹Ÿå¯ä»¥ç›´æ¥é€‰æ‹©é€‰æ‹©æ˜¾å¡ï¼Œè¾“å…¥`CUDA_VISIBLE_DEVICES=0 python train.py`ä¹Ÿå¯ä»¥

